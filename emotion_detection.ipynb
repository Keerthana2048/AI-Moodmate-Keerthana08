{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c9e187-e378-4272-8e32-eb3cf017c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! This program will detect your emotion using your face.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to start your camera... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is now ON.\n",
      "Look at the camera and press the letter 'q' when you want to capture your face.\n",
      "Got your image! Now I’ll analyze your emotion...\n",
      "\n",
      "Your detected emotion is: SAD\n",
      "Thank you for using the Emotion Detector!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "print(\"Hello! This program will detect your emotion using your face.\")\n",
    "input(\"Press Enter to start your camera...\")\n",
    "\n",
    "# Step 3: Turn on the webcam (camera 0 is usually the built-in one)\n",
    "camera = cv2.VideoCapture(0)\n",
    "print(\"Camera is now ON.\")\n",
    "print(\"Look at the camera and press the letter 'q' when you want to capture your face.\")\n",
    "\n",
    "# Step 4: Show live camera feed until 'q' is pressed\n",
    "while True:\n",
    "    success, frame = camera.read()\n",
    "    if not success:\n",
    "        print(\"Oops! Could not access the camera.\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Emotion Detection Window\", frame)\n",
    "\n",
    "    # Capture image and analyze when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Got your image! Now I’ll analyze your emotion...\")\n",
    "        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        if isinstance(result, list):\n",
    "            result = result[0]\n",
    "        mood = result['dominant_emotion']\n",
    "        print(f\"\\nYour detected emotion is: {mood.upper()}\")\n",
    "        break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Thank you for using the Emotion Detector!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb60aba-7d00-4516-b1ad-8e0a7788e715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
