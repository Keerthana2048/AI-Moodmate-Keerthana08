{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ab0fb7-549c-4940-89eb-c2228cec977a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18647 images belonging to 5 classes.\n",
      "Found 4661 images belonging to 5 classes.\n",
      "Found 5834 images belonging to 5 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "\n",
      "🔹 Stage 1: Training top layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keert\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 1s/step - accuracy: 0.3231 - loss: 1.5720 - val_accuracy: 0.3819 - val_loss: 1.4890 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 1s/step - accuracy: 0.3725 - loss: 1.4863 - val_accuracy: 0.4186 - val_loss: 1.4387 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 1s/step - accuracy: 0.3844 - loss: 1.4710 - val_accuracy: 0.4151 - val_loss: 1.4452 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1794s\u001b[0m 3s/step - accuracy: 0.3928 - loss: 1.4662 - val_accuracy: 0.4010 - val_loss: 1.4473 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 1s/step - accuracy: 0.3953 - loss: 1.4590 - val_accuracy: 0.4244 - val_loss: 1.4268 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4022s\u001b[0m 7s/step - accuracy: 0.3982 - loss: 1.4536 - val_accuracy: 0.4306 - val_loss: 1.4265 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 1s/step - accuracy: 0.4019 - loss: 1.4506 - val_accuracy: 0.4396 - val_loss: 1.4079 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1s/step - accuracy: 0.4005 - loss: 1.4507 - val_accuracy: 0.4201 - val_loss: 1.4152 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 1s/step - accuracy: 0.4060 - loss: 1.4457 - val_accuracy: 0.4370 - val_loss: 1.4102 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1s/step - accuracy: 0.4059 - loss: 1.4453 - val_accuracy: 0.4252 - val_loss: 1.4171 - learning_rate: 0.0010\n",
      "Epoch 11/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 1s/step - accuracy: 0.4097 - loss: 1.4345 - val_accuracy: 0.4385 - val_loss: 1.4035 - learning_rate: 2.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 1s/step - accuracy: 0.4172 - loss: 1.4299 - val_accuracy: 0.4375 - val_loss: 1.4065 - learning_rate: 2.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 906ms/step - accuracy: 0.4145 - loss: 1.4299 - val_accuracy: 0.4441 - val_loss: 1.4019 - learning_rate: 2.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 1s/step - accuracy: 0.4207 - loss: 1.4279 - val_accuracy: 0.4342 - val_loss: 1.4079 - learning_rate: 2.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 822ms/step - accuracy: 0.4204 - loss: 1.4223 - val_accuracy: 0.4426 - val_loss: 1.3952 - learning_rate: 2.0000e-04\n",
      "\n",
      "🔹 Stage 2: Fine-tuning the full model...\n",
      "Epoch 1/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 798ms/step - accuracy: 0.3607 - loss: 1.4612 - val_accuracy: 0.4587 - val_loss: 1.3348 - learning_rate: 1.0000e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 899ms/step - accuracy: 0.4257 - loss: 1.3822 - val_accuracy: 0.4718 - val_loss: 1.3094 - learning_rate: 1.0000e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 945ms/step - accuracy: 0.4577 - loss: 1.3396 - val_accuracy: 0.4825 - val_loss: 1.2751 - learning_rate: 1.0000e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 931ms/step - accuracy: 0.4732 - loss: 1.3140 - val_accuracy: 0.5055 - val_loss: 1.2536 - learning_rate: 1.0000e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 981ms/step - accuracy: 0.4882 - loss: 1.2935 - val_accuracy: 0.5010 - val_loss: 1.2283 - learning_rate: 1.0000e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 1s/step - accuracy: 0.5079 - loss: 1.2638 - val_accuracy: 0.5291 - val_loss: 1.2077 - learning_rate: 1.0000e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 1s/step - accuracy: 0.5197 - loss: 1.2460 - val_accuracy: 0.5308 - val_loss: 1.2038 - learning_rate: 1.0000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 1s/step - accuracy: 0.5290 - loss: 1.2284 - val_accuracy: 0.5366 - val_loss: 1.1913 - learning_rate: 1.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 1s/step - accuracy: 0.5263 - loss: 1.2267 - val_accuracy: 0.5520 - val_loss: 1.1547 - learning_rate: 1.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 1s/step - accuracy: 0.5426 - loss: 1.2078 - val_accuracy: 0.5462 - val_loss: 1.1658 - learning_rate: 1.0000e-05\n",
      "Epoch 11/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 1s/step - accuracy: 0.5503 - loss: 1.1925 - val_accuracy: 0.5561 - val_loss: 1.1461 - learning_rate: 1.0000e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 998ms/step - accuracy: 0.5596 - loss: 1.1812 - val_accuracy: 0.5589 - val_loss: 1.1355 - learning_rate: 1.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 991ms/step - accuracy: 0.5592 - loss: 1.1746 - val_accuracy: 0.5589 - val_loss: 1.1416 - learning_rate: 1.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 959ms/step - accuracy: 0.5688 - loss: 1.1641 - val_accuracy: 0.5711 - val_loss: 1.1120 - learning_rate: 1.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 1s/step - accuracy: 0.5737 - loss: 1.1555 - val_accuracy: 0.5752 - val_loss: 1.1053 - learning_rate: 1.0000e-05\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 1s/step - accuracy: 0.5656 - loss: 1.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Accuracy: 56.56%\n",
      "\n",
      "✅ Model saved as mobilenetv2_fear_5class_optimized.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset Setup\n",
    "# -----------------------------\n",
    "extract_dir = \"./fear_dataset\"\n",
    "train_dir = os.path.join(extract_dir, \"train\")\n",
    "test_dir = os.path.join(extract_dir, \"test\")\n",
    "\n",
    "selected_classes = ['angry', 'fear', 'happy', 'sad', 'surprise']\n",
    "\n",
    "IMG_SIZE = (160, 160)  # higher resolution for MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# -----------------------------\n",
    "# Data Generators\n",
    "# -----------------------------\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.7,1.3],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=selected_classes,\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=selected_classes,\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=selected_classes,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Class weights to handle imbalance\n",
    "# -----------------------------\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = train_data.classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(classes), y=classes)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# -----------------------------\n",
    "# Model Definition\n",
    "# -----------------------------\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# -----------------------------\n",
    "# Callbacks\n",
    "# -----------------------------\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# -----------------------------\n",
    "# Compile Stage 1 (Frozen)\n",
    "# -----------------------------\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n🔹 Stage 1: Training top layers...\")\n",
    "history1 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Stage 2: Fine-tuning\n",
    "# -----------------------------\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False  # freeze first 100 layers\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n🔹 Stage 2: Fine-tuning the full model...\")\n",
    "history2 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate on Test Data\n",
    "# -----------------------------\n",
    "test_loss, test_acc = model.evaluate(test_data, verbose=1)\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"mobilenetv2_fear_5class_optimized.h5\")\n",
    "print(\"\\n✅ Model saved as mobilenetv2_fear_5class_optimized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3b5ddf-fe09-4488-9c0b-3a72cfa99a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 380ms/step\n",
      "✅ Manual Accuracy: 56.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on test data\n",
    "pred_probs = model.predict(test_data)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = test_data.classes  # these are actual class indices\n",
    "\n",
    "# Compute accuracy\n",
    "acc = accuracy_score(true_classes, pred_classes)\n",
    "print(f\"✅ Manual Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdaaac1a-bed7-429d-b856-a550bb1d7a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 341ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.45      0.43      0.44       958\n",
      "        fear       0.41      0.10      0.16      1024\n",
      "       happy       0.81      0.75      0.78      1774\n",
      "         sad       0.40      0.77      0.53      1247\n",
      "    surprise       0.76      0.61      0.68       831\n",
      "\n",
      "    accuracy                           0.57      5834\n",
      "   macro avg       0.57      0.53      0.52      5834\n",
      "weighted avg       0.59      0.57      0.55      5834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions\n",
    "pred2 = model.predict(test_data)\n",
    "pred_labels = np.argmax(pred2, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, pred_labels, target_names=selected_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a0f1d-9ed0-4550-8a1e-0d846cebf520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
